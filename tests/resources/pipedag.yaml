name: pipedag_tests
table_store_connections:
  postgres:
    args:
      # Postgres: this can be used after running `docker-compose up`
      url: "postgresql://{$POSTGRES_USERNAME}:{$POSTGRES_PASSWORD}@127.0.0.1:6543/{instance_id}"
      create_database_if_not_exists: true

  mssql:
    args:
      # SQL Server: this can be used after running `docker-compose up`
      url: "mssql+pyodbc://{$MSSQL_USERNAME}:{$MSSQL_PASSWORD}@127.0.0.1:1433/{instance_id}?driver=ODBC+Driver+18+for+SQL+Server&encrypt=no"
      create_database_if_not_exists: true

  ibm_db2:
    args:
      # SQL Server: this can be used after running `docker-compose up`
      url: "db2+ibm_db://db2inst1:password@localhost:50000/testdb"
      schema_prefix: "{instance_id}_"
      create_database_if_not_exists: false

  duckdb:
    args:
      url: "duckdb:///{$TMPDIR}{instance_id}.duckdb"

instances:
  __any__:
    # listen-interface for pipedag context server which synchronizes some task state during DAG execution
    network_interface: "127.0.0.1"
    # classes to be materialized to table store even without pipedag Table wrapper (we have loose coupling between
    # pipedag and pydiverse.transform, so consider adding 'pydiverse.transform.Table' in your config)
    auto_table: ["pandas.DataFrame", "sqlalchemy.sql.elements.TextClause", "sqlalchemy.sql.selectable.Selectable"]
    # abort as fast a possible on task failure and print most readable stack trace
    fail_fast: true

    instance_id: pipedag_default
    table_store:
      table_store_connection: postgres
      class: "pydiverse.pipedag.backend.table.SQLTableStore"
      args:
        # print select statements before being encapsualted in materialize expressions and tables before writing to
        # database
        print_materialize: true
        # print final sql statements
        print_sql: true

    blob_store:
      class: "pydiverse.pipedag.backend.blob.FileBlobStore"
      args:
        base_path: "/tmp/pipedag/blobs"

    lock_manager:
      class: "pydiverse.pipedag.backend.lock.ZooKeeperLockManager"
      args:
        hosts: "localhost:2181"

    orchestration:
      class: "pydiverse.pipedag.engine.SequentialEngine"

  # Instances used by pytest

  ## Database Instances

  postgres:
    instance_id: pd_postgres
    table_store:
      table_store_connection: postgres
      args:
        unlogged_tables: false

  postgres_unlogged:
    instance_id: pd_postgres_unlogged
    table_store:
      table_store_connection: postgres
      args:
        unlogged_tables: true

  mssql:
    instance_id: pd_mssql
    table_store:
      table_store_connection: mssql
      args:
        disable_pytsql: true

  mssql_pytsql:
    instance_id: pd_mssql_pytsql
    table_store:
      table_store_connection: mssql
      args:
        disable_pytsql: false
        pytsql_isolate_top_level_statements: true

  ibm_db2:
    instance_id: pd_ibm_db2
    stage_commit_technique: READ_VIEWS
    table_store:
      table_store_connection: ibm_db2

  ibm_db2_avoid_schema:
    instance_id: pd_ibm_db2_avoid_schema
    stage_commit_technique: READ_VIEWS
    table_store:
      table_store_connection: ibm_db2
      args:
        avoid_drop_create_schema: true

  duckdb:
    instance_id: pd_duckdb
    stage_commit_technique: READ_VIEWS
    table_store:
      table_store_connection: duckdb

  ## Table Cache Instances

  local_table_cache:
    instance_id: local_table_cache
    table_store:
      local_table_cache:
        class: "pydiverse.pipedag.backend.table_cache.ParquetTableCache"
        args:
          base_path: "/tmp/pipedag/table_cache"

  local_table_cache_inout:
    instance_id: local_table_cache_inout
    table_store:
      local_table_cache:
        store_input: true
        store_output: true
        use_stored_input_as_cache: true
        class: "pydiverse.pipedag.backend.table_cache.ParquetTableCache"
        args:
          base_path: "/tmp/pipedag/table_cache"

  local_table_store:
    instance_id: local_table_store
    table_store:
      local_table_cache:
        store_input: true
        store_output: true
        use_stored_input_as_cache: false
        class: "pydiverse.pipedag.backend.table_cache.ParquetTableCache"
        args:
          base_path: "/tmp/pipedag/table_cache"

  ## Orchestration Engine Instances

  dask_engine:
    instance_id: dask_engine
    orchestration:
      class: "pydiverse.pipedag.engine.DaskEngine"
      args:
        num_workers: 8
